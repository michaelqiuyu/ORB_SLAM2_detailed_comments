orb-slam2系统运行细节：
	1. 跟踪线程：负责对每帧图像的相机位置进行定位，并决定什么时候插入新的关键帧
		输入配置文件，词袋→读取配置文件、词袋→跟踪


		1.1 对每一张图像执行
			1.1.1 特征选择：使用ORB特征（后续可以修改为sift特征，同时注意有没有地方使用了sift词袋）
				从图像帧提取的所有ORB特征（256维），不管其是否已经关联了地图云点， 这些ORB特征点都经过畸变模型矫正过。

			1.1.2 特征提取：单目每张图片提取n个特征，双目提取2n个特征
				1. 构建图像金字塔：根据缩放因子进行缩放，对得到的图像在上下左右四个方向上添加一个宽度为19的buffer，保证能够在边界上提取到特征点；填充buffer中的像素，使用的方式是以边界为对称轴进行填充，比如abc|dcba；
				   每层特征点数目分配：特征点的数目按照面积在每一层进行分配，也就是面积越大分配的特征点越多；实际上，ORB-SLAM2中使用的是面积开方
				作为比例因子进行分配，也就是以构建图像金字塔的缩放因子来进行分配。由于整数的缘故，最上层的数目为总数减去其它层的数目

				2. fast特征提取：使用cell(边为30)在没有buffer的图像上进行划分，然后条用opencv借口获得fast角点；由于每个cell所能获得的角点数量并不确定，统一先存储，最后进行分配。最好将存储的vector尽可能设置大，否则可能后面cell提取的fast角点无法保存了；
				   fast角点：对每一个像素点，根据半径3画出一个圆，与16个像素相交，然后判断是否有连续的12个像素值大于或者小于这个像素点的灰度

				3. 四叉树对特征点进行分配：对金字塔图像，第一次分裂：均分为4份，删除没有特征点的；第二次分裂，对每一份，如果只有一个特征点就保持不变，如果有超过一个特征点的话就分为四份，删除没有特征点的，比较此时小快的数量是否超过了所需的特征点数目，如果是的话，就在每一个小块中选择一个最好的特征点（提取fast角点的时候会有响应值，响应值越大，角点越好），否则继续分裂；注意每次分裂的时候，先分裂特征点数目多的快
				
				4. 计算特征点方向：对某一层，根据scale计算半径，越上层的图像半径越大（乘以1/s）；计算一个圆形（半径为15）区域内的灰度质心；使用圆形的原因是保证对每一个方向同等对待，使用相同的权值；由于像素都是整数的缘故，这里会有一些技巧，使得所得到的一个点序列是一个近似圆形，实际计算的是每一行中最大的u和最小的u，注意这里只计算1/4的圆，其余部分通过对称性得到

			1.1.3 描述子计算：先对图像计算高斯模糊（高斯平滑），保留主要特征，使图像不那么尖锐；使用给定的pattern选择256个点对，判断每个点对的灰度值的大小判断结果，构成一个256维（32 * 8）的向量

			1.1.4 根据特征点所在的金字塔的层级，将特征点的坐标反算到原始图像中

			1.1.5 根据opencv对获得的特征点去畸变（读取配置文件）：此处去畸变是计算特征点畸变前的坐标，与对整张图像去畸变不一样；计算图像去畸变的边界，这里选择原始图像的四个边界点执行去畸变，获得新的四个边界点，然后获得u_min, v_min, u_max, v_max，从而得到图像边界

			1.1.6 将特征点分配到网格中，这里网格的尺寸为48 * 64


		1.2 初始化
			单目必须通过初始化才能得到三维点，双目可以通过基线直接计算三维点，rgbd可以直接读取深度得到三维点

			1.2.1 单目初始化 
				1. 执行初始化的条件：
					1.1 只有在连续两帧（注意这里是连续的两帧）的特征点数目多于100的时候才执行初始化
					1.2 匹配的数目要超过100才执行初始化

				2. 特征点匹配：
					2.1 对每一个特征点按照GetFeaturesInArea(此处是Frame的，KeyFrame中也有),搜索待定的匹配点集合，这里只在原始图像上搜索
					2.2 GetFeaturesInArea：根据给定的圆心和半径(100偏大)在指定的金字塔层级上搜索匹配点（这里一般仅为初次搜索）
						获取与圆相交的cell得到cell内的特征点，对每一个特征点，只有其在圆内并且对应的金字塔层级在给定的层级区间内就认为满足要求
					2.3 对每一个待定的匹配点，根据描述子，计算最优的匹配和次优的匹配，判断最优匹配的距离 < TH_LOW(50) && 最有匹配的距离 < mfNNratio * 次优匹配的距离（初始化中mfNNratio较大为0.9，条件更容易满足）；如果条件成立，就记录匹配信息，并计算两个匹配点的旋转角的偏差，并将偏差值记录到对应的直方图中
					2.4 以30度为一个矩形构建直方图，然后得到数量最多的三个直方，删除其余直方中对应的匹配信息

				3. 最小样本计算：使用随机数的方法在0~N-1之中产生iteration（默认200）个最小样本集，也就是有iteration个vector，每个vector中有8个下标

				4. 单应矩阵计算：使用8点法进行计算（最少4个点）
					1. 特征点归一化：使用均值和平均绝对偏差进行归一化，所以计算得到的H矩阵并非是最初的单应矩阵
					2. DLT求解单应矩阵：p2 = H * p1，使用最小二乘进行计算H（基于SVD）
					3. 由于进行了归一化，这里求解最初的单应矩阵H12，并求解逆矩阵H21
					4. 使用卡方检验计算单应矩阵得分：重投影误差为二维相片坐标误差，因此卡方检验的自由度为2，显著性水平为0.05；具体为：
						4.1 根据p2 = H21 * p1计算p1在图片2中的相片坐标，由于采用齐次坐标，因此这里的等号实际是平行，这样才能计算u,v
						4.2 p2与实际的p2的距离d并除以方差，也就是默认每一维都是0均值的正太分布（并不一定是正太，需要看指定的方差）
						4.3 如果高于卡方检验的阈值则不计分，并将这个匹配标记为false，否则得分为th - d*
						4.4 根据p1 = H12 * p2计算p2在图片1中的相片坐标，得分计算同上
						4.5 计算所有匹配的总得分作为H的得分
					5. 迭代iteration次，获得得分最高的那个H并记录得分SH

				5. 基础矩阵计算：使用8点法计算F；Hartey就认为利用8点法求基础矩阵不稳定的一个主要原因就是原始的图像像点坐标组成的系数矩阵A不好造成的，而造成A不好的原因是像点的齐次坐标各个分量的数量级相差太大，因此需要归一化
					1. 特征点归一化：使用均值和平均绝对偏差进行归一化，所以计算得到的F矩阵并非是最初的原始矩阵
					2. DLT求解基础矩阵：p2^T * F * p1 = 0，使用最小二乘计算F（基于SVD）
					3. 由于F矩阵的秩为2（由本质矩阵决定），对计算得到的F的进行SVD分解，并将最小的奇异值直接置0，然后再次相乘得到F
					4. 由于进行了归一化，这里求解最初的基础矩阵F，注意这里没有计算你矩阵
					5. 根据卡方检验计算基础矩阵得分：使用某点到其极线的距离，因此卡方检验的自由苏为1，显著性水平为0.05，具体为：
						5.1 F * p1表示图片2的极线方程，然后计算p2到极线的距离并除以方差为d
						5.2 卡方阈值为th=3.841，得分阈值为thScore = 5.991；如果d>th则不得分，并将这个匹配标记为false，否则得分为thScore - d
						5.3 F^T * p2表示图片1的极线，同理计算得分
						5.4 计算所有匹配点的得分
					6. 迭代iteration次，获得得分最高的那个F并记录得分SF

				6.特征点归一化处理：对原始的图像坐标做同向性变换，可以减少噪声的干扰，大大的提高8点法的精度。预先对图像坐标进行归一化有以下好处：
					1. 能够提高运算结果的精度利用归一化处理后的图像坐标，对任何尺度缩放和原点的选择是不变的。
					2. 归一化步骤预先为图像坐标选择了一个标准的坐标系中，消除了坐标变换对结果的影响。归一化操作分两步进行，首先对每幅图像中的坐标进行平移（每幅图像的平移不同）使图像中匹配的点组成的点集的形心（Centroid）移动到原点；接着对坐标系进行缩放使得各个分量总体上有一样的平均值，各个坐标轴的缩放相同的

				7. 卡方检验：
					1. 单目H的自由度为2，单目F的自由度为1，双目自由度为3（多了视差）
					2. 方差计算，0层方差为1，层级越高，方差按照s^2指数增长

				8. SH/(SH+SF) > 0.4就选择单应矩阵分解，从这里看出更倾向于选择但应矩阵

				9. 单应矩阵分解：Faugeras SVD-based decomposition
					1. 仅仅计算d1 > d2 > d3的情形，此时只有2中情况（d = +-d2），又由于每种情况又有4种情况，总计有8种情况，得到8组R, t
					2. 对每一组R t，对所有的匹配点（标记为true）进行三角化获得三维点，并计算好的三角化点的数目
						2.1 判断其在两个坐标系下的深度是否均为正
						2.2 O1→p→O2的夹角是否大于0.36度（需要一定的平移量，否则视差太小，深度值计算不会准确）
						2.3 将三维点分别投影到两张图片做重投影误差的卡方检验，此处的阈值为4；如果通过则为好点，计数加1
						2.4 获取一个O1→p→O2的夹角：如果通过的点的数目小于50，就选择角度最小的那个；否则选择从大到小排序的第50个（注意这里选择的并不是最大的视差角度）
					3. 根据通过的点的数目得到最优的模型和次优的模型，主要保存有最优模型的通过点的数目num1、所选择的视差角parallax对应的R t的下标（即哪一个R t）、合格的三维点，以及特征点是否成功三角化的标志；次优模型的通过点的数目num2
					4. 只有在num1 * 0.75 > num2 && parallax > 阈值(1) && num1 > 三角化点的阈值(50) && num1 > 0.9 * 标记为true的匹配总数的时候才认为得到了好的R t，否则认为失败

				10. 基础矩阵分解：
					1. 计算本质矩阵，按照14讲得到4组解，并对每一组解（R t）按照上面的方式进行检验，得到每一组通过的点的个数
					2. maxGood = max(nGood1,max(nGood2,max(nGood3,nGood4)))；nMinGood = max(static_cast<int>(0.9*N), minTriangulated)，其中minTriangulated为三角化点的阈值；每一组通过的点的数目 > maxGood则nsimilar加1，只有maxGood > nMinGood &&  nsimilar = 1才往下执行；
					3. 获得使得nsimilar=1的那一组的R、t，并记录三角化的三维点（通过了筛选的），视差角parallax以及特征点是否成功三角化的标志，只有在parallax > 阈值(1)的时候才认为得到了好的R t，否则认为失败

			1.2.2 删除无法三角化的匹配；设置位姿：第一帧位姿为单位T，第二帧为求得的R、t（注意这里的t是一个单位化向量，但并不是尺度就会这样选择）

			1.2.3 初始化成功后对地图点进行的操作
				1 将初始化帧和当前帧均设置为关键帧并加入到地图中，并计算两帧的BOW向量
				2 将成功三角化的匹配点加入到地图中，并设置其参考关键帧为当前关键帧（注意这里当前帧和当前关键帧实际上相同）；再将三维点加入到初始化的两帧之中，记录的是每一帧中哪个特征点（记录下标）与哪个三维点对应；对每一个三维点添加其观测的关键帧（注意只有关键帧，没有普通帧）
				3. 对地图点计算最优的描述子以及方向和观测距离
					3.1 最优的描述子：获取所有观测到这个地图点的相机中特征点的描述子，对每一个描述子计算其与其他描述子之间的距离的中值，获取最小中值所对应的那一个描述子
					3.2 观测方向：计算所有观测到这个地图点的相机的原点到地图点的单位方向，然后对这些方向求平均
					3.3 观测距离：金字塔层数越小，图片尺寸越大，图片越清晰，看到的也就越远，因此对于某个地图点，其距离参考关键帧的距离为d，其在参考关键帧的金字塔尺度为m:
						最远应该在第0层，此时d_max = d * 1.2^m，
						最近在最上层，此时d_min = d / 1.2^(n - 1 - m) = d_max / 1.2^(n - 1)
						使用这个这个关系可以预测某个地图点的尺度，也就是log_1.2(d_max/d)
				4. 将地图点加入到当前帧（注意这里不是关键帧）中
				5. 更新初始两帧之间的连接关系
				6. Optimizer::GlobalBundleAdjustemnt优化地图点和位姿，迭代次数为20次
				7. 尺度归一化：获取所有地图点计算其在初始化帧（第一帧，这里使用当前关键帧也就是第二帧也可以）下的深度的中值；然后对t除以中值深度并更新当前关键帧和当前帧的位姿，对每一个地图点，三维坐标均除以这个中值深度。并对以下信息进行更新：
					7.1 将此时的初始化两帧加入到局部地图中的关键帧集合中以及局部建图句柄中；将所有的地图点加入到局部地图中，将局部地图加入到地图中
					7.2 最后一个关键帧的ID为当前关键帧的ID，最后一个关键帧为点前关键帧；最后一帧设置为当前帧，当前帧的参考关键帧为当前关键帧（实际上这两个是一个图片）
					7.3 设置当前track的参考关键帧为当前关键帧
					7.4 将第一帧加入到初始关键帧中（在回环中有用）

		1.3 初始化成功，开始跟踪
			1.3.1 CheckReplacedInLastFrame：由于局部建图线程可能替换了地图点，在这里将最后一帧对应的地图点进行替换
				需要注意的是，地图点替换知识地图点数据发生改变，每张照片保存的地图点没有变化，由于需要上一帧的地图点，因此需要进行替换；替换主要发生在局部建图线程中的SearchInNeighbors中

			1.3.2 刚刚初始化是没有速度的，此时使用参考关键帧跟踪；如果有了速度后是恒速模型跟踪，如果恒速模型失败就是用参考关键帧跟踪；跟丢了是重定位
				1. 关键帧跟踪
					1.1 SearchByBoW：这里参数是关键帧与普通帧，不同于回环的时候的均为关键帧；将关键帧的地图点往普通帧投影
						1. 取出关键帧中有好的地图点的特征点，FeatureVector，构建直方图；取出当前普通帧的FeatureVector
						2. 根据FeatureVector进行快速匹配，获得与每一个关键帧中的特征点匹配的普通帧的特征点，保存匹配信息
							描述子最小且小于阈值，最佳距离<次佳距离*mfNNratio（0.7）
						3. 直方图旋转角度一致性检验，获取数量最多的三组
					1.2 如果匹配数目<15就认为跟踪失败；否则将上一帧的位姿（不是参考关键帧的）作为当前帧位姿的初始值
					1.3 对当前帧的位姿进行优化，地图点不优化；地图点不动是因为地图点是之前初始化BA或者局部建图BA出来的，认为是准的，此处只有位姿不准，因此仅仅优化位姿
						1. 优化构建的是一元边，记录边的数量，小于3不执行优化
						2. 做4次优化，每次迭代10次；每次优化后，据重投影误差做卡方检验（自由度为2，显著性0.05）删除外点，下次优化的时候只使用内点
						3. 保存当前帧的位姿，记录外点匹配和内点匹配
					1.4 根据外点匹配删除保存的匹配信息
					1.5 只有当成功内点匹配的数量大于等于10才算跟踪成功

				2. 恒速模型跟踪
					2.1 UpdateLastFrame：由于普通帧没有位姿，保存的是相对于参考关键帧的相对位姿，因此据此计算最后一帧的位姿
					2.2 根据恒速模型计算当前帧的位姿mVelocity*mLastFrame.mTcw作为初始值
					2.3 SearchByProjection：参数为当前帧和上一帧；将上一帧跟踪的地图点投影到当前帧，并且搜索匹配点。用于跟踪前一帧
						1. 对于前一帧的每一个非外点的地图点，将其投影到当前帧，要求深度为正；坐标在去畸变后的图片边界内；
						2. 获取地图点对应的上一帧的特征点，获得金字塔尺度s，计算当前帧的搜索范围GetFeaturesInArea，搜索尺度为s-1~s+1
							radius = th*CurrentFrame.mvScaleFactors[nLastOctave]，其中th=15（双目7）
						3. 遍历候选的特征点，获取最优匹配（描述子距离最小且小于阈值）；一旦当前帧的某个特征点与某个三维点匹配，后续就不在匹配当前帧的这个特征点了（可以优化，如果已经有匹配了，计算那种匹配的描述子距离更小）
						4. 直方图旋转角度一致性检验，获得数量最多的三组，删除其余匹配信息
					2.4 如果匹配数量太少(20)，就扩大th(2倍)再一次进行SearchByProjection；如果匹配数量还是小于20，就认为跟踪失败
					2.5 按照1.3的方式优化位姿，依然保持地图点不动
					2.6 按照1.4的方式删除外点匹配
					2.7 只有当成功内点匹配的数量大于等于10才算跟踪成功

				3. 重定位
					3.1 计算当前帧的词袋信息
					3.2 DetectRelocalizationCandidates：用词袋模型找到与当前帧相似的候选关键帧（也可以使用GPS信息进行近邻查找） 
						1. 遍历词袋的word，对每一个叶子节点获得归属于它的关键帧，然后计算每个关键帧与当前帧具有相同的word数量，保存有相同word的关键帧
						2. 统计与当前帧具有最大相同word的数量num1，并定义最小数量为num2=num1*0.8
						3. 遍历候选的重定位关键帧，要求关键帧与当前帧的相同word数量>num2，满足要求时使用mpVoc->score(F->mBowVec,pKFi->mBowVec)计算当前帧与此关键帧的分数，并保存关键帧及其得分(pair类型)，计数有多少这样的关键帧
						4. 遍历上面得到的候选关键帧，计算最优得分和最优累计得分，初值均为候选关键帧对应的分数
							1. 对每一个关键帧得到10帧共视关键帧，对每一个共视关键帧，如果其也在4中的候选关键帧中，将共视关键帧对应的得分加到累计得分中，并比较这个得分与当前的最优得分更新最优得分
							2. 保存累计得分和最优得分对应的关键帧
							3. 获得最高的累计得分
						5. 将最高的累计得分*0.75作为阈值，获得累计得分在此之上的组，并保存此组对应的最有得分对应的关键帧
						6. 将上面得到的关键帧作为重定位的候选关键帧
					3.3 对每一个候选关键帧，用1.1中的SearchByBoW搜索匹配，如果匹配<15就跳过，并删除这个候选关键帧；否则就构建EPNP求解器，求解器的参数为最小内点数量10，最大迭代数量300，最小计算集合4，内点判断阈值：自由度为2，显著性为0.05；计算迭代次数的概率0.99
					3.4 对每一个候选关键帧，执行EPNP算法（指定迭代5次）
						1. 在mnIterations<mRansacMaxIts||nCurrentIterations<nIterations的条件中进行循环，在此循环中执行EPNP算法；每次得到结果计算内点数量如果内点数量<最小的内点数量就跳过，否则与最优内点(最初为0）比较更新最后内点，此时还会更新位姿信息等
						2. 位姿求精：
							使用所有的内点（前面只使用4点）做EPNP得到结果，然后检测内点，如果内点数量>最小内点阈值(10)，就认为找到了最好的EPNP结果了，EPNP求解结束，返回位姿结果
						3. 位姿求精失败则继续循环内求解EPNP结果
						4. 循环退出且mnIterations>=mRansacMaxIts（此条件导致的退出）,如果此时的最优内点数量大于最小内点阈值就返回最优内点对应的位姿，并记录bNoMore=true
						5. 如果求得的位姿非空，就记录当前帧的位姿，并将EPNP得到的内点关联到当前帧，然后执行PoseOptimization（只优化位姿，不优化地图点），获得优化后的内点（内部依然会有内点检测-卡方检验）；如果内点数目<10个就跳过；否则依据优化得到的外点删除当前帧的外点（对应点置空）；若内点<50，SearchByProjection（10，窗口较大，用于GetFeaturesInArea）：参数为当前帧和候选关键帧
							1. 将候选关键帧中没有与当前帧匹配的三维点投影到当前帧，需要满足
								深度为正、像素坐标在当前帧内(去畸变后的图像边界)、距离当前帧相机距离是否在范围内(d_min*0.8~d_max*1.2)
							2. 获得三维点的尺度，据此搜索半径；在投影点处使用GetFeaturesInArea搜索候选匹配
							3. 根据描述子获得最优匹配
							4. 进行直方图旋转角度一致性检验获得前三组，删除其余的匹配；返回正确的匹配数（这个为额外增加的）
						6. 如果内点+额外匹配>=50，就再次执行PoseOptimization优化位姿，获得优化后的内点数目；如果此时内点数目在30~50
							1. 记录新增的内点匹配，后续投影匹配中就会跳过
							2. 再次使用SearchByProjection（窗口较小，为3）搜索匹配；如果内点+新增匹配大于50，就再次PoseOptimization优化位姿，输出结果，结束循环；
						7. 如果重定位成功，就结束循环，不在遍历后面的候选关键帧了
					3.5 返回重定位是否成功的标志，并记录最后一次重定位成功的ID（mnLastRelocFrameId），也就是当前帧的ID

			1.3.3 只要跟踪成功（无论哪一种跟踪）就会进行局部地图跟踪TrackLocalMap，进一步优化位姿
				1. UpdateLocalMap：更新局部关键帧 mvpLocalKeyFrames 和局部地图点 mvpLocalMapPoints
					1.1 UpdateLocalKeyFrames：更新局部关键帧
						1. 获取与当前帧有共视的所有关键帧（一级共视），并获得共视最多的关键帧，如果一级共视帧数量>80直接到4
						2. 获得每一个一级共视关键帧的前10帧共视关键帧，以及一级共视关键帧的父关键帧和子关键帧
						3. 将上面的一级共视关键帧和二级共视关键帧和父关键帧和子关键帧全部存储到局部关键帧中
						4. 将track和当前帧的参考关键帧设置为一级共视关键帧里面共视最多的关键帧
					1.2 UpdateLocalPoints：更新局部关键点。先把局部地图清空，然后将局部关键帧的有效地图点添加到局部地图中
						1. 清空局部地图点
						2. 添加局部关键帧中所有关键帧对应的所有非坏的地图点
				2. SearchLocalPoints：用局部地图点进行投影匹配，得到更多的匹配关系
					2.1 遍历当前帧的地图点，进行标记，在后面遍历所有的局部地图点的时候，碰到这里的地图点就跳过
					2.2 遍历局部地图点，判断地图点是否在当前帧的视野范围内，isInFrustum：依次经过以下判断
						1. 将这个地图点变换到当前帧的相机坐标系下，如果深度值为正才能继续下一步
						2. 将地图点投影到当前帧的像素坐标，如果在图像有效范围内才能继续下一步
						3. 计算地图点到相机中心的距离，如果在有效距离范围内才能继续下一步
						4. 计算当前相机指向地图点向量和地图点的平均观测方向夹角，小于60°才能进入下一步（实际上是挑选生成这个地图点的关键帧们左右接近的，而非对向或远离的）
						5. 根据地图点到光心的距离来预测一个尺度（仿照特征点金字塔层级）
						6. 记录相关信息
					2.3 记录在当前帧视野范围内的所有地图点，并计数，计数>0往下执行
					2.4 SearchByProjection：参数为某一帧和地图点；将局部地图点往当前帧上投影计算匹配
						1. 对每一个地图点，使用GetFeaturesInArea获取候选匹配信息，关于搜索半径r的计算为：
							已知当前相机指向地图点向量和地图点的平均观测方向夹角angle，如果angle<3.6°，那么r=2.5；否则r=4；当然和还需要乘以金字塔带来的尺度
						2. 候选特征点已经有三维点的跳过；获得与地图点匹配的最优和次优的特征点；如果最优匹配的距离小于阈值并且满足最优与次优的关系，就记录这匹配信息
						3. 注意这里没有直方图一致性检验

				3. 根据上面获得的内点匹配执行PoseOptimization(单帧)优化位姿；对内点的地图点的观测更新(+1)并记录跟踪到的地图点的数目
					3.1 如果最近刚刚发生了重定位,那么成功跟踪的地图点的数目至少50个点才认为是成功跟踪，否则失败
					3.2 如果是正常的状态话只要跟踪的地图点大于30个就认为成功，否则失败

			1.3.4 如果上面三种跟踪都失败了
				1. 如果剩余轨迹长度<80米，就将这条轨迹删除；否则重置系统，重新开始

			1.3.5 如果某种跟踪成功
				1. 如果上一帧的位姿存在，那么计算mVelocity = mCurrentFrame.mTcw*LastTwc，否则置空即可；删除当前帧中观测次数为0的地图点
				2. 决定是否插入关键帧
					1. 为什么需要关键帧
						相近帧之间信息冗余度很高，关键帧是取局部相近帧中最有代表性的一帧，可以降低信息冗余度。举例来说，摄像头放在原处不动，普通帧还是要记录的，但关键帧不会增加。关键帧选择时还会对图片质量、特征点质量等进行考察，在Bundle Fusion、RKD SLAM等RGB-DSLAM相关方案中常常用普通帧的深度投影到关键帧上进行深度图优化，一定程度上关键帧是普通帧滤波和优化的结果，防止无用的或错误的信息进入优化过程而破坏定位建图的准确性。如果所有帧全部参与计算，不仅浪费了算力，对内存也是极大的考验，这一点在前端vo中表现不明显，但在后端优化里是一个大问题，所以关键帧主要作用是面向后端优化的算力与精度的折中，使得有限的计算资源能够用在刀刃上，保证系统的平稳运行。假如你放松ORB_SLAM2关键帧选择条件，大量产生的关键帧不仅耗计算资源，还会导致local mapping 计算不过来，出现误差累积
					2. 选择关键帧
						1. 考虑方向：
							1.1 关键帧自身质量要好，例如不能是非常模糊的图像、特征点数量要充足、特征点分布要尽量均匀等等；
							1.2 关键帧与其他关键帧之间的关系，需要和局部地图中的其他关键帧有一定的共视关系但又不能重复度太高，以达到既存在约束，又尽量少的信息冗余的效果
						2. 指标：
							2.1 距离上一关键帧的帧数是否足够多（时间）。比如我每隔固定帧数选择一个关键帧，这样编程简单但效果不好。比如运动很慢的时候，就会选择大量相似的关键帧，冗余，运动快的时候又丢失了很多重要的帧。
							2.2 距离最近关键帧的距离是否足够远（空间）/运动比如相邻帧根据pose计算运动的相对大小，可以是位移也可以是旋转或者两个都考虑，运动足够大（超过一定阈值）就新建一个关键帧，这种方法比第一种好。但问题是如果对着同一个物体来回扫就会出现大量相似关键帧。
							2.3 跟踪局部地图质量（共视特征点数目）记录当前视角下跟踪的特征点数或者比例，当相机离开当前场景时（双目或比例明显降低）才会新建关键帧，避免了第2种方法的问题。缺点是数据结构和逻辑比较复杂。
						3. orb-slam2的选择
							orbslam2做的非常好，跟踪线程选择关键帧标准较宽松，局部建图线程再跟据共视冗余度进行剔除，尤其是在回环检测中使用了以关键帧为代表的帧“簇”的概念，回环筛选中有一步将关键帧前后10帧为一组，计算组内总分，以最高分的组的0.75为阈值，滤除一些组，再在剩下的组内各自找最高分的一帧作为备选帧，这个方法非常好地诠释了“关键帧代表局部”的这个理念。
					3. 具体操作
						1. 什么时候不插入关键帧
							1.1 仅仅跟踪的时候
							1.2 局部地图线程被闭环检测使用的时候
							1.3 距离上一次重定位比较近并且关键帧数目超过最大限制mMaxFrames（限制为相机帧率，settings.yaml中），此处有疑问：tracking.cc的1520行）
						2. 计算满足观测数目的参考关键帧中地图点的数目nRefMatches
							2.1 地图中的关键帧数目<=2，观测数目要>=2
							2.2 地图中的关键帧数目>2，观测数目要>=3
						3. 设置当前帧和参考关键帧跟踪到的点的比例thRefRatio，比例越大，越倾向于增加关键帧
							3.1 只有一个关键帧的时候：0.4
							3.2 单目：0.9
							3.3 其他：0.75
						4. 计算以下条件：
							4.1 当前帧的ID >= 最后一帧关键帧的ID + mMaxFrames，也就是很久没有插入关键帧了
							4.2 当前帧的ID >= 最后一帧关键帧的ID + mMinFrames并且bLocalMappingIdle（局部建图线程是否允许插入）
							4.3 跟踪到的点的数量15 < mnMatchesInliers < nRefMatches*thRefRatio；mnMatchesInliers为当前帧中经过了TrackLocalMap后得到的好的地图点；跟踪到的地图点不能太多也不能太少
						5. 做出决定：
							4.1和4.2至少有一个成立，4.3必须成立；然后bLocalMappingIdle为true就插入，否则就不插入
						6. 插入关键帧
							6.1 如果局部建图线程关闭就不插入了
							6.2 将当前帧作为关键帧，当前帧的参考关键帧也是这个关键帧；track的参考关键帧更新为当前关键帧，将这个关键帧加入到局部地图中，将最后一帧关键帧更新为当前关键帧

				3.  删除当前帧的那些在bundle adjustment中检测为outlier的地图点

			1.3.6 记录相关信息：
				如果当前帧的位姿非空，就保存当前帧相对于参考关键帧的位姿；否则直接保存mlRelativeFramePoses的最后一个（此时最后两个数相同）

		1.4 共视图、本质图、扩展图
			1.4.1 共视图
				共视图是无向加权图，每个节点是关键帧，如果两个关键帧之间满足一定的共视关系（至少15个共同观测地图点）他们就连成一条边，边的权重就是共视地图点数目
			1.4.2 扩展树
				对每一个关键帧，计算与其具有最多共视的关键帧作为它的父关键帧来形成父子关系，以此构建树结构
			1.4.3 本质图
				共视图比较稠密，本质图比共视图更稀疏，这是因为本质图的作用是用在闭环矫正时，用相似变换来矫正尺度漂移，把闭环误差均摊在本质图中。本质图中节点也是所有关键帧，但是连接边更少，只保留了联系紧密的边来使得结果更精确。本质图中包含：
					1. 扩展树连接关系
					2. 形成闭环的连接关系，闭环后地图点变动后新增加的连接关系
					3. 共视关系非常好（至少100个共视地图点）的连接关系
			1.4.4 本质图优化和全局BA结果对比
				1、全局BA存在收敛问题。即使迭代100次，相对均方误差RMSE 也比较高
				2、essential graph 优化可以快速收敛并且结果更精确。θmin表示被选为essentialgraph至少需要的共视地图点数目，从结果来看，θmin的大小对精度影响不大，但是较大的θmin值可以显著减少运行时间
				3、essential graph 优化后增加全局 full BA 可以提升精度（但比较有限），但是会耗时较多


	2. 局部建图：负责处理新的关键帧，对周围的相机位姿进行局部BA以优化重构
		track线程只要创建一个关键帧就会往局部建图线程中插入，一旦局部建图线程开启，局部建图线程就不再接受track送来的关键帧了（等局部建图结束就能接受了），由于track很快，因此一般局部建图结束后，又会有很多关键帧插入到局部建图线程中等待局部建图

		2.1 对局部建图中的每一帧执行
			2.1.1 SetAcceptKeyFrames(false)：设置不在接受关键帧

			2.1.2 ProcessNewKeyFrame：每次处理局部建图关键帧列表中最前面的关键帧并令其为当前关键帧，并将其从局部建图关键帧列表中移除
				1. 计算当前帧的BOW
				2. 遍历当前帧的所有地图点，验证地图点是否在当前帧中（不是几何验证，而是这个地图点的观测中是否有这个关键帧），如果是的话，就计算地图点的方向、深度范围、最佳描述子；否则的话就将它加入到mlpRecentAddedMapPoints中，等待MapPointCulling函数的检验
				3. UpdateConnections：更新关键帧之间的连接图
					1. 获得一级共视关键帧（只要有共视即可）
					2. 对一级共视关键帧进行遍历，如果共视>15就建立共视图关系并保存pair<共视，共视关键帧>的pair列表，并使用AddConnection更新这个共视关键帧的连接信息并获得共视最多的共视关键帧
					3. 如果pair列表为空（表明没有共视数量>15的），就将共视最多的那一帧和当前帧建立共视图，并保存此pair；
					4. 对pair进行排序，依据是共视程度，从小到大；然后分别保存pair列表中的共视关键帧和共视（分两个VECTOR）
					5. 存储当前关键帧的共视信息（共视关键帧和权重等）；更新当前帧的父关键帧，对应的父关键帧的子关键帧就是当前帧（生成树）；如果以后还有地方对这个关键帧调用了UpdateConnections，那么不在重新计算父子关系了，也就是生成后就不更新父子关系了

					AddConnection：参数为关键帧和权重（权重就是共视数量）；建立共视关系
						1. 如果当前帧的连接帧中有参数中的关键帧，就更新权重
						2. 如果没有的话新建这个关系（连接以及给与权重）
				4. 将当前关键帧添加到局部地图中

			2.1.3 MapPointCulling：检查新增地图点，根据地图点的观测情况剔除质量不好的新增的地图点
				1. 遍历mlpRecentAddedMapPoints中的每一个地图点，如果isBad就从mlpRecentAddedMapPoints中删除
				2. mnFound/mnVisible小于0.25就设置pMP->SetBadFlag()并从mlpRecentAddedMapPoints中删除；mnFound表示跟踪（匹配上）到该地图点的普通帧帧数，mnVisible表示观测到该地图点的普通帧数量（只要在普通帧的事业范围内）；pMP->SetBadFlag()表示告知可以观测到该MapPoint的Frame，该MapPoint已被删除
				3. 从该点建立开始到现在已经过了不小于2个关键帧&&观测到该点的相机数却不超过阈值th，就设置pMP->SetBadFlag()并从mlpRecentAddedMapPoints中删除；th=2（双目为3）
				4. 从建立该点开始，已经过了3个关键帧而没有被剔除，则认为是质量高的点；仅从mlpRecentAddedMapPoints中删除

			2.1.4 CreateNewMapPoints：用当前关键帧与相邻关键帧通过三角化产生新的地图点，使得跟踪更稳
				1. 获取20帧共视关键帧，构建匹配器，此处匹配器的阈值比较严格（阈值为0.6，并且不做直方图一致性检验了）
				2. 对每一个共视关键帧，计算三维点的深度中值d1，然后计算两个相机的距离（相当于基线）d2，得到基线/景深，如果比值太小（0.01）就跳过
				3. 计算两帧之间的基础矩阵，用于SearchForTriangulation，然后使用SearchForTriangulation获得匹配
				4. 对每一对匹配，计算O1→P→O2的角度theta，theta需要满足1 < theta < 90，对应通过的匹配构建三角化计算三维坐标
				5. 这个三维点必须在两个相机的前方，否则不要
				6. 计算三维点在当前关键帧和共视帧下的重投影误差（自由度2，显著性0.05）进行卡方检验
				7. 计算三维点距离两个相机中心的距离d1和d2以及他们在两帧的尺度s1和s2，由于“近大远小”，所以k1=d1/s1约等于k2=d2/s2；只要k1<3*k2或者k2<3*k1，那么就认为满足这个要求
				8. 将三维点包装为地图点添加到地图以及对应的两帧中，并计算描述子、方向、深度范围
				9. 将地图点添加到mlpRecentAddedMapPoints中，进行检验（会删除一些地图点）

				SearchForTriangulation: 对已知位姿的两帧构建三角化，此时已知基础矩阵
					1. 计算相机1在相机2中的投影，也就是极点
					2. 获取两帧的FeatureVector，然后开始遍历，对帧1和帧2中相同的节点，获得这个节点对应的帧1和帧2的特征点集合
					3. 对帧1的每一个特征点，首先要求其没有对应的三维点（有的话就不用三角化了），在帧2的特征点（也没有对应的三维点）中搜索与其描述子距离小于阈值且距离最小的特征点，计算这个特征点距离极点的距离，如果接近就跳过（不能与极点太接近），计算特征点到极线的距离是否在与之范围内
					4. 记录匹配信息，并将匹配的旋转角的差值记录到直方图中
					5. 直方图一致性检验，保留数量最多的三组，删除其余匹配，并更新匹配信息（这里并不做这个环节）

			2.1.5 将当前关键帧插入到回环中，注意第1个关键帧不能加入进去，因为第1个关键帧定义了世界坐标系

			2.1.5 查看是否有复位线程的请求并接受track的关键帧（为什么又接受，如果每次处理了一帧又进来一帧，局部BA是否得到所有图像运行结束才执行？）

			2.1.6 检查当前线程是否结束

			2.1.7 休眠3毫秒，这里休眠的原因是什么

		2.3 当最后一帧也按照2.2处理结束后
			2.3.1 SearchInNeighbors：检查并融合当前关键帧与相邻关键帧（两级相邻）中重复的地图点
				1. 获取当前关键帧的20个一级共视帧，对每一个一级共视帧，再获取5个二级共视关键帧，讲这两级共视关键帧全部保存；获取当前帧的全部地图点
				2. 将当前帧的地图点往共视关键帧投影进行融合；遍历共视关键帧，每次执行matcher.Fuse(pKFi,vpMapPointMatches)：将地图点投影到关键帧中进行匹配和融合
					1. 对每一个不是isBad的地图点，检查其是否已经是共视帧的地图点了，如果是就跳过，否则
					2. 将地图点投影到关键帧，要满足：深度为正、在图像范围内、到相机距离满足范围(d_min*0.8~d_max*1.2)、与光心连线夹角与地图点夹角在60度以内，如果条件都通过的话就往下执行
					3. GetFeaturesInArea搜索候选匹配，半径为3 * 对应的尺度；获得最优匹配且距离小于给定阈值且通过卡方检验(2, 0.05)，要求匹配的特征点有正常的对应的三维点，将三维点替换为观测次数Observations更多的那个地图点
					4. 如果匹配的特征点没有对应的三维点，就将当前帧的这个地图点设置为这个共视帧的地图点，并给这个地图点添加一个观测信息
					5. 只要特征点匹配正确了（无论是否有三维点对应）就计数，并将最后结果返回
				3. 收集所有共视关键帧的好的地图点，并将他们全部往当前帧进行投影做融合，执行matcher.Fuse，具体同上
				4. 由于融合的地图点一定是当前帧的地图点(不管是当前帧往共视帧投影还是共视帧往当前帧投影)，因此只需遍历当前帧的地图点，更新地图点的描述子、方向、深度范围(由于地图点的参考关键帧-第一次创建时的关键帧不变，因此深度范围不变)
				5. 由于有关键点的融合，共视关系发生了变化，更新当前关键帧的共视关系UpdateConnections

			2.3.2 LocalBundleAdjustment：优化当前局部建图关键帧的位姿和地图点（方式为什么是选择当前帧的共视帧进行优化，而不是局部建图中的关键帧，答案可能是当前帧的共视帧一定包括了局部建图线程中的关键帧）
				1. 获得所有的共视关键帧及其对应的有效的地图点
				2. 遍历有效的地图点，获得地图点观测到的关键帧，从中筛选出不是1中的共视关键帧的关键帧，这些关键帧不优化，但需要固定住
				3. 第一个关键帧是不优化的
				4. 添加位姿顶点和地图点，构建边，边缘化地图点，使用HuberKernel（卡方检验，2，0.05）进行优化，优化分两次
					1. 初始优化后，计算每一条边的误差是否>5.991(2, 0.05)或者边链接的地图点深度值为负，那么设置这条边不优化了
					2. 设置边不适用HuberKernel，认为误差没有那么大了，再次执行BA优化；
						1. 如果边的误差>5.991或者边链接的地图点深度值为负，就记录pair<KF, pMP>，形成pair列表
						2. 根据这个pair列表，删除关键帧的这个地图点，并删除这个地图点对应的这个观测
				5. 更新关键帧位姿；更新地图点位置，计算地图点方向和深度范围

			2.3.3 KeyFrameCulling：删除冗余的关键帧；注意这里删除的不是当前的关键帧而是当前关键帧的共视关键帧
				1. 获取当前关键帧的所有共视关键帧GetVectorCovisibleKeyFrames(有序的)，并遍历，碰到初始第一帧跳过
				2. 对每一个共视关键帧，获得所有有效的地图点，通过以下方式计算共视关键帧的nRedundantObservations冗余度量
					1. 对每一个地图点，获得其观测的关键帧，如果有thObs(3)个及以上的观测的关键帧(不包括这个共视关键帧自己)满足在更低的尺度观测到这个地图点(scaleLeveli<=scaleLevel+1，scaleLevel为地图点在共视关键帧上的金字塔尺度，scaleLeveli为观测的关键帧上的金字塔的尺度；尺度越小，观测越准)，那么nRedundantObservations++
				3. 如果某个共视关键帧中90%以上的有效地图点被判断为冗余的，也就是nRedundantObservations>0.9*nMPs，那就删除这个共视关键帧

		注意：局部建图线程中的关键帧一旦处理完成后，此时的当前关键帧就是局部建图线程中最后一个关键帧


	3. 闭环检测：负责对每个新的关键帧都要进行闭环搜索，以确认是否形成闭环；局部建图线程插入的关键帧在mlpLoopKeyFrameQueue中
		在一个while(true)中执行一下语句，除非发生某些情况，否则不会退出    查看退出条件

		3.1 CheckNewKeyFrames：检测mlpLoopKeyFrameQueue(第一帧不在里面)是否为空，非空往下执行

		3.2 DetectLoop
			3.2.1 取出mlpLoopKeyFrameQueue的front（第一帧）作为当前关键帧帧，距离上次闭环没多久（小于10帧），或者map中关键帧总共还没有10帧，则不进行闭环检测，返回false，并将当前关键帧添加到mpKeyFrameDB，设置当前关键帧不进行回环检测；否则往下执行

			3.2.2 获得当前关键帧的所有共视关键帧GetVectorCovisibleKeyFrames（结果有序），并根据词袋模型计算当前关键帧与每一个共视关键帧的相似度得分，获得最低得分

			3.3.3 DetectLoopCandidates：参数为当前关键帧和最低得分；在mpKeyFrameDB中找到与该关键帧可能闭环的关键帧
				1. 获得所有连接关键帧（类似与获得共视关键帧，只是GetVectorCovisibleKeyFrames的结果有序）GetConnectedKeyFrames(结果无序)
				2. 获取当前关键帧的有相同单词的关键帧，并且这些关键帧又不是1中的连接关键帧，并记录满足要求的关键帧与当前关键帧具有相同的word的个数，将这些关键帧添加到候选闭环的关键帧列表中，并记录这些关键帧的mnLoopQuery为当前关键帧的ID；使用词袋模型实现
				3. 计算闭环候选的关键帧中与当前关键帧具有最多相同的word数量max_num，并计算min_num=max_num*0.8
				4. 从候选闭环的关键帧中挑选与当前帧的相同word数量在min_num之上且两帧之间mBowVec得分在参数中的最低得分之上的关键帧，并保存信息pair<si, pKFi>，其中si表示mBowVec，pKFi表示候选闭环的关键帧，最后得到这样一个pair列表
				5. 单单计算某一关键帧的得分不稳定，这里使用关键帧组的概念；遍历pair列表，获得每一个pKFi的最好的10个共视关键帧，计算最优得分和累计得分
					1. 最优得分和累计得分的初始值都是pair中的si
					2. 只有某个共视关键帧在2中得到的候选闭环关键帧之中而且相同单词数量>min_num时，才计算累计得分；判断是否需要更新最优得分
					3. 保存每一个pKFi对应的累计得分和最优得分对应的关键帧
					3. 计算累计得分的最高分max_score
				6. 设置最低分的阈值min_score=max_score*0.75
				7. 对pair列表，如果其pKFi的累计得分大于min_score，及记录其最优得分最优的关键帧；由此得到一个候选闭环的关键帧列表

				注意：一般的连接或者共视关键帧都是空间上或者时间上比较接近的，而且由于长时间的尺度漂移，当前关键帧不会与闭环帧形成连接或者共视关系（对应相同特征的地图点距离较远，取决于尺度漂移的程度；如果实际上形成了共视，那么说明长时间没有尺度漂移，当然不用做回环矫正了）

			3.3.4 如果候选闭环的关键帧为空，就添加当前关键帧到mpKeyFrameDB，设置当前关键帧不进行回环检测，清空mvConsistentGroups，返回false

			3.3.5 清空mvpEnoughConsistentCandidates(最重筛选得到的闭环帧)、创建vCurrentConsistentGroups(当前连续组)
				1. 对3.3中得到的闭环候选的关键帧进行遍历，对每一个候选闭环关键帧：
					1.1 获得这个候选闭环关键帧的连接关键帧GetConnectedKeyFrames（无序）为spCandidateGroup（加上自己pCandidateKF）
					1.2 记录连续性达标的标志bEnoughConsistent、bConsistentForSomeGroup
					1.3 如果此时mvConsistentGroups（程序运行一直在更新）为空，那么只需要创建make_pair(spCandidateGroup,0)并添加到vCurrentConsistentGroups中即可（此时遍历结束就将vCurrentConsistentGroups赋值给mvConsistentGroups，显然此时没有得到mvpEnoughConsistentCandidates，不会形成最后的闭环候选关键帧）
					1.4 如果此时mvConsistentGroups（程序运行一直在更新）不为空，遍历mvConsistentGroups判断每一个连续组是否和spCandidateGroup有交集（也就是mvConsistentGroups[iG]中是否含有spCandidateGroup中的某个关键帧），如果有，则获得mvConsistentGroups[iG]连续次数并将其连续次数加1赋值给nCurrentConsistency并添加到make_pair(spCandidateGroup,nCurrentConsistency)并添加进vCurrentConsistentGroups；需要注意的是如果spCandidateGroup与多个mvConsistentGroups[iG]有交集，那么每次都会添加上面信息到vCurrentConsistentGroups（从这里可以看到vCurrentConsistentGroups中可能有相同的元素，也就是spCandidateGroup与多个mvConsistentGroups[iG]相交且连续性又恰好相同的时候），并且一旦某个mvConsistentGroups[iG]与spCandidateGroup相交了，那么尽管它与后面的某个spCandidateGroup又相交了，此时的相交信息也不会写进vCurrentConsistentGroups了，但是对后面的spCandidateGroup，只要连续性达标了，依然会执行1.5的
					1.5 判断nCurrentConsistency>=mnCovisibilityConsistencyTh(3)，如果满足就将pCandidateKF（注意不是spCandidateGroup，仅仅添加候选闭环关键帧，不包括共视连接）添加到mvpEnoughConsistentCandidates中，并设置bEnoughConsistent也就是之后不再添加这个pCandidateKF了
				2. 将vCurrentConsistentGroups赋值给mvConsistentGroups，以此来对其进行更新
				3. 将当前关键帧添加到mpKeyFrameDB；判断mvpEnoughConsistentCandidates是否为空，如果是返回false，当前帧闭环检测失败；否则返回true，表示检测到了连续性达标的闭环候选帧了

		3.3 ComputeSim3
			3.3.1 遍历mvpEnoughConsistentCandidates，对每一个候选关键帧，使用SearchByBoW计算两者的匹配
				1. SearchByBoW：参数均为关键帧；主要思路是利用FeatureVector匹配特征点（同一个featurenode下描述子距离最小且小于阈值且满足最佳与次佳的比例关系）、然后进行直方图一致性检验，而且匹配的特征点都需要有对应的地图点（后面要利用他们进行sim3求解）
				2. 匹配数目<20就跳过；否则，构建sim3求解器，参数为连个关键帧以及1中得到的匹配，使用ransac方式求解，概率0.99，最小内点20，最多迭代300，并将sim3求解器添加到列表，后面统一求解

			3.3.2 对上面的sim3求解器列表遍历，设定迭代参数：迭代5次；
				1. sim3迭代求解；内点数目<最小内点20，则失败
				2. 满足mnIterations<mRansacMaxIts && nCurrentIterations<nIterations此条件的情况下使用随机数构建多个最小集
				3. 对每一个最小集，计算sim3，然后进行内点检测CheckInliers
					1. CheckInliers：检测内点的数量；将帧1的匹配点往帧2投影获得err1（平方距离），将帧2的匹配点往帧1投影获得err2，要求一对匹配的err1和err2都小于阈值（2，0.01，不同于0.05，更容易满足了）才是内点
				4. 获得内点数目最多的那一组sim3结果，并且只要内点数目超过了最小内点就立即停止，返回在此时前的最好模型（不再往后面计算了，这里可以修改为一直求得具有最多内点数目的模型未知，也就是全部遍历一遍），并记录内点信息

			3.3.3 如果sim3求解失败，就继续下一个sim3求解，否则
				1. 根据上面记录的内点信息，修改匹配信息
				2. 使用SearchBySim3在当前关键帧和候选闭环关键帧之间搜索更多的匹配
					SearchBySim3：对当前关键帧和闭环候选帧搜索更多的匹配信息，已知s R t，并且已经有了部分匹配
						1. 记录已经有了的匹配关系
						2. 将当前帧的特征点对应的地图点(注意这里是地图点而不是特征点，并且还没有匹配的)投影到候选帧（使用的是R、t、s），深度为负则跳过；计算像素坐标，不在图像跳过；
						3. 计算最大距离和最小距离：最大距离为地图点的最大距离*1.2；最小距离为地图点的最小距离*0.8，判断投影点距离相机的距离是否在这个距离范围内
						4. PredictScale预测金字塔尺度，根据尺度获取搜索半径，根据GetFeaturesInArea(KeyFrame，逻辑类似于Frame中的，并且没有了尺度判断)搜索候选匹配
						5. 对候选点遍历获得描述子距离最近且在阈值范围内并且尺度与PredictScale预测的金字塔尺度接近的，记录1→2的匹配信息
						6. 将候选帧的地图点投影到当前帧，重复上面的过程，记录2→1的匹配
						7. 只有1→2和2→1都能匹配上的才算正确匹配，并返回新增匹配的数目
						8. 由于1往2投影的时候1中的是三维点，2往1投影的时候2中的是三维点，所以这里实际上做的是三维点的匹配
				3. 根据1中的修改后的匹配和2中获得的匹配执行Optimizer::OptimizeSim3优化sim3的结果，仅优化位姿，不优化地图点
					1. 构建位姿顶点、构建地图点顶点（不优化，固定）
					2. 构建边，边的误差为：现将地图点根据各自的R、t变换到各自的相机下，然后e12表示相机2中的地图点经过sim3变换到相机1中再投影到图片后的重投影误差，e21类似，使用HuberKernel
					3. 第一次优化先迭代5次，获得结果，然后计算边的误差，根据阈值th（10）剔除掉误差大的边（删掉这些边，相当于没有了这些3D-3D之间的匹配，匹配信息也同步更新了）；如果有边的误差>th，就设置第二次优化迭代次数为10；否则为5
					4. 如果剔除误差较大的匹配后剩余的匹配<10，就返回false，优化失败；否则执行第二次优化，再次根据阈值th记录误差大的匹配，最后返回sim3结果和好的匹配数量（也就是内点数量）

				4. 如果3中最后结果的内点数量>=20，那么不再继续求解sim3了，认为此时求解的sim3就是满足要求的，此时的候选闭环关键帧就是闭环关键帧了，保存位姿（位姿为mg2oScw = gScm*gSmw，也就是世界到当前帧的位姿）、尺度、内点信息；否则继续往后遍历sim3求解

			3.3.4 sim3求解结束
				1. 如果适中都没有求得满足要求的sim3变换，那么对mvpEnoughConsistentCandidates中的所有关键帧不做闭环检测了，对当前帧也不做闭环检测了（设置SetErase()即可），返回false，表示闭环失败；否则
				2. 获得闭环关键帧及其共视帧（GetVectorCovisibleKeyFrames()，有序），对这些关键帧获得他们对应的地图点并添加到mvpLoopMapPoints中
				3. 使用SearchByProjection：参数为当前关键帧、sim3结果、2中的地图点，阈值th=10；获得更多的匹配并存入mvpCurrentMatchedPoints
					1. 将所有有效的且还没有与当前关键帧匹配的地图点往当前关键帧进行投影（注意这里只使用了R、t没有使用s，此处应该有问题，此时尺度还没有矫正），判断：深度为正、在矫正后的图像边界内、距离相机距离满足要求、相机-地图点连线与地图点的方向射线的夹角在60°以内，如果都满足
					2. 计算地图点尺度PredictScale，根据尺度确定搜索半径，使用GetFeaturesInArea获得候选匹配
					3. 从中得到尺度接近的（预测尺度和匹配的特征点尺度）、还没有匹配的当前关键帧的特征点，并计算最优匹配且匹配距离在阈值范围内的得到匹配信息，记录匹配信息，返回匹配数量
				4. 无论是之前构造的匹配还是3中新增的匹配，获得匹配数目
					1. 如果匹配数目<40，那么设置mvpEnoughConsistentCandidates中的关键帧和当前关键帧都不进行闭环了（SetErase()），返回false，否则
					2. 设置mvpEnoughConsistentCandidates中的所有的非闭环关键帧不进行闭环了（SetErase），返回true

		3.4 CorrectLoop
			3.4.1 mpLocalMapper->RequestStop()：请求局部地图停止，防止在回环矫正时局部地图线程中InsertKeyFrame函数插入新的关键帧

			3.4.2 如果当前有全局BA在运行，那么停止这个全局BA，记录全局BA的次数；等待局部建图线程结束，并等待1毫秒

			3.4.3 UpdateConnections：更新当前关键帧的共视连接关系，具体上面已经有定义了

			3.4.4 获得当前关键帧及其共视关键帧的列表mvpCurrentConnectedKFs(GetVectorCovisibleKeyFrames)，更新这些关键帧的地图点和位姿，注意更新的只是当前帧及其共视关键帧
				1. 位姿传递路径：w→m→c→w→i；这里会计算mvpCurrentConnectedKFs中每一关键帧的w→i的位姿，并存入CorrectedSim3中
					1.1 w→m：世界到闭环关键帧的位姿，已知
					1.2 m→c：闭环关键帧到当前帧的sim3变换，已知
					1.3 c→w：当前帧的位姿，已知
					1.4 w→i：第i帧（mvpCurrentConnectedKFs中的）的位姿，已知
				2. 更新地图点：获得vKF的每一关键帧的所有有效地图点，执行P_w→i→w→c→m→w（从这里看出前两步互逆，没必要，直接计算P_w→c即可）得到新的世界系坐标
				3. 更新位姿：根据w→m→c→w→i获得世界到第i个关键帧的变换，此时不是一个变换矩阵，其中杂糅着sim3变换和T变换，将旋转部分变为旋转矩阵，将平移部分除以尺度s，比如最后结果为[[sR, t], [0, 1]]，那么结果为R、t/s，理论依据见论文注释
				4. 将mvpCurrentConnectedKFs中的关键帧的位姿分别保存到CorrectedSim3、NonCorrectedSim3；其中CorrectedSim3中保存着经过了sim3的位姿，也就是3中更新的位姿，NonCorrectedSim3中保存的是原本的位姿，没有sim3变换

			3.4.5 mvpCurrentMatchedPoints记录着当前帧对应的闭环关键帧及其共视关键帧的地图点，在这里认为匹配的地图点更准，因为他们在起点不远处，尺度偏移基本没有，很精确，比已经矫正的当前帧上的地图点更精确，因此
				1. 遍地mvpCurrentMatchedPoints，如果当前帧上也有这个点，如mvpCurrentMatchedPoints[i]与mpCurrentKF->GetMapPoint(i)均存在，那么用mvpCurrentMatchedPoints[i]替换mpCurrentKF->GetMapPoint(i)（由于都是指针操作，因此当前帧对应的地图点也变了）；如果mpCurrentKF->GetMapPoint(i)不存在，那么将mvpCurrentMatchedPoints[i]添加到当前帧，mvpCurrentMatchedPoints[i]这个地图点添加当前帧这个观测并重新计算描述子

			3.4.6 SearchAndFuse：将闭环相连关键帧组mvpLoopMapPoints 投影到当前关键帧组mvpCurrentConnectedKFs中，进行匹配，新增或替换当前关键帧组中KF的地图点
				1. 遍历CorrectedSim3，对每一关键帧及其位姿（包含了sim3变换），执行matcher.Fuse：将mvpLoopMapPoints往这一关键帧投影
					1.1 获得不含尺度的位姿，其实这里可以直接使用3.4.4中3更新的位姿，使用这个位姿而不是含有sim3的位姿是因为这个位姿才是正确的，没有尺度漂移的，依据这个位姿得到的匹配才是合理的
					1.2 将mvpLoopMapPoints中每一个有效的且不在关键帧中的地图点，如果深度为正、在图像范围内、距离相机距离满足要求（d_min*0.8~d_max*1.2）、地图点与相机连线与地图点方向的夹角在60°以内
					1.3 预测地图点尺度，根据尺度计算半径，使用GetFeaturesInArea获得候选匹配
					1.4 从候选匹配中找到尺度接近预测尺度的、距离最小的、距离在阈值范围内的匹配，获得这个特征点对应的三维点（特征点不一定有三维点）
					1.5 如果这个三维点存在，就认为这个三维点需要被替换，记录这个替换信息到vpReplacePoint（这里不能直接替换，原因是需要对地图点加锁后才能替换，否则可能会crash）；如果这个三维点不存在，那么将mvpLoopMapPoints此时遍历的地图点添加到关键帧，并给这个地图点添加观测（当前这个关键帧）
					1.6 只要能找到满足阈值的匹配特征点，就计数到nFused，并返回这个值
				2. 加锁之后，根据vpReplacePoints对地图点进行替换

			3.4.7 遍历mvpCurrentConnectedKFs，对每一关键帧执行一下操作，得到每一关键帧的不包括其本身的共视信息和当前帧及其共视信息的共视信息，也就是仅仅由于闭环产生的共视信息
				1. 获得此关键帧的共视关键帧vpPreviousNeighbors
				2. 更新此关键帧的共视关系UpdateConnections
				3. 再次获得此关键帧的共视关键帧，注意此时共视关系已经更新了，包含了由于闭环而添加的共视，将信息记录到LoopConnections（字典）
				4. 从LoopConnections中删除vpPreviousNeighbors的信息，也就是此关键帧的共视关键帧不包括原始共视关键帧了
				5. 从LoopConnections中删除mvpCurrentConnectedKFs，也就是此关键帧的共视关键帧不包括当前帧及共视关键帧了

			3.4.8 OptimizeEssentialGraph：本质图优化，位姿图优化，仅优化位姿，不优化地图点，优化的是sim3变换而不是T变换
				1. 获得当前地图中所有的关键帧和地图点
				2. 设置位姿顶点：如果关键帧在CorrectedSim3中，就用经过了sim3的位姿（尺度不为1）；如果不在，就是用原来的位姿（尺度为1），并将所有的位姿保存到vScw（字典，关键帧ID到位姿的映射）中；如果关键帧是当前的闭环关键帧，那么就不优化这个位姿，而是以这个位姿为基准进行优化
				3. 设置边：有4中类型的边
					3.1 LoopConnections：闭环时因为地图点调整而出现的关键帧间的新连接关系
						对于每一条边，表示两个位姿之间的相对变化（从第i个关键帧到第j个关键帧的位姿），位姿从vScw中获得，很显然，此时有的位姿是经过了sim3的，有的不是，根据关键帧ID获取即可；如果这条边对应的两个关键帧中有一个为当前关键帧或者闭环帧，那么对两个关键帧的共视就没有要求，否则要求两个关键帧之间至少有100个共视地图点
					3.2 生成树的边，也就是父子关系
						遍历地图中的所有关键帧，对每一个关键帧，获得其原始的位姿（不经过sim3变换，不管其是否在CorrectedSim3中），获得其父关键帧的原始位姿，然后获得父子之间的相对位姿
					3.3 当前帧与闭环匹配帧之间的连接关系（注意不包括当前关键帧和闭环帧，此时这个关系还没有写进到关键帧与闭环帧的匹配信息中，至于不包括当前这个回环的原因是当前关键帧与其闭环关键帧之间的关系是sim3，这里使用的都是T关系，当然在这里我认为应该加入当前帧和闭环帧的闭环关系，但是必须按照3.4.4中的3那样计算得到两帧之间的T关系，去除sim3的影响）
						获得当前关键帧之前的闭环匹配关系，然后得到原始的位姿（T关系），计算相对位姿
					3.4 共视程度超过100的关键帧也作为边进行优化
						取出共视超过100的连接关键帧，使用原始的位姿计算相对位姿，当然这里需要判断前面是否已经添加了这条边（比如这条边是父子关系，前面已经添加了）
				4. 开始g2o优化，迭代次数20次，得到优化结果vCorrectedSwc（注意存储的是sim3变换）
					4.1 根据优化得到的sim3位姿计算新的位姿T，也就是将旋转部分去除尺度，并对平移除以尺度，并将位姿结果存储到关键帧中，思路类似于3.4.4中的3；
					4.2 对每一个地图点，计算其参考的关键帧，如果地图点的mnCorrectedByKF为当前关键帧（也就是CorrectedSim3中的关键帧的地图点），那么关键帧的参考的关键帧为当前关键帧，否则，其参考的关键帧为参考关键帧（创建这个地图点的那个关键帧）；根据vScw将坐标从世界系转换到参考的关键帧，然后使用vCorrectedSwc将坐标变换到世界系，存储坐标结果并更新方向和深度范围
				5. 特别注意：
					1. 本质图优化过程中只固定了闭环关键帧，第一关键帧（构建世界系的初始关键帧）并没有固定，因此本质图优化后，初始化关键帧的位姿不再是I、0，而是发生了变化，因此世界系不再是第一个关键帧的相机系，所有关键帧的位姿也不再是相对于第一个关键帧的位姿，当然这个具体的位置可以根据第一个关键帧的位姿反算得到，等价于本质图优化之前的第一个关键帧的位姿（请注意深刻理解这一点）。这一点在发生回环的测试数据的结果中可以明显看到；如果没有回环的话，测试数据的结果中初始关键帧的位姿为I、0.
					2. 这里并没有引入第三方传感器测量相对位姿，而位姿图优化能够进行的原因在于我们对同一个关键帧位姿，在某些时候，我们使用的是sim3变换后的位姿构建边，在有时候使用的是原始位姿构建的边

			3.4.9 将当前关键帧和闭环关键帧之间的闭环关系加入到闭环关系列表中

			3.4.9 RunGlobalBundleAdjustment：全局BA，优化位姿和地图点
				1. GlobalBundleAdjustemnt：对地图中的所有关键帧位姿和地图点进行优化，注意这里优化的是T而不是sim3了，上面已经将sim3的尺度均摊到每一关键帧了，而且关键帧的位姿也更新了
					1.1 迭代次数10次
					1.2 根据闭环关键帧的计算过程可以知道，闭环关键帧几乎处处不是第一个关键帧，因此
					1.3 优化得到的结果并不会直接写入到位姿结果中，而是会进行记录到pKF->mTcwGBA中，并标记pKF->mnBAGlobalForKF = nLoopKF；地图点也是类似处理pMP->mPosGBA、pMP->mnBAGlobalForKF = nLoopKF；注意此时的位姿不再是相对于第一个关键帧的，而是相对于本质图优化之前第一个关键帧的，世界系已经发生了变化。
				2. 在global BA过程中local mapping线程仍然在工作，这意味着在global_BA时可能有新的关键帧产生，但是并未包括在GBA里，而且这些关键帧都是针对本质图优化前的第一个关键帧的位姿的，本质图优化后，世界系已经发生了改变，需要将这些关键帧的位姿以及地图点进行更新
					2.1 对地图中的所有关键帧进行遍历，如果它的mnBAGlobalForKF=nLoopKF，那么直接将pKF->mTcwGBA结果写入到位姿中即可；如果这些关键帧是local mapping中新产生的，获得他的父关键帧（这个父关键帧必须是已经矫正了的，也就是说要么它的nBAGlobalForKF = nLoopKF，也就是在GlobalBundleAdjustemnt已经优化并标记了，要么就是已经经过它的父关键帧矫正了（这个父关键帧同样要满足nBAGlobalForKF = nLoopKF的要求）），先通过父关键帧的没有矫正的位姿（本质图优化后，GlobalBundleAdjustemnt优化前）计算父子之间的变换，然后根据父关键帧的已经矫正的位姿pKF->mTcwGBA计算这个关键帧的位姿，相当于根据父关键帧优化前后的位姿为桥梁得到子关键帧的位姿，具体实现是spanning_tree
					2.2 spanning_tree：如果已经有m个关键帧了，再来一个关键帧，那么它的父关键帧肯定在已有的m个关键帧中了，也就是它的父关键帧一定是这m个关键帧中的某一个；地图从第一个关键帧开始建立的，也就是第二个关键帧的父关键帧是第一个关键帧，第三个关键帧的父关键帧的一定在前两个关键帧里面，也就是必定是第一个关键帧的后代（要么为儿子要么为孙子），从这里可以看出第一个关键帧没有父关键帧，但是后面的所有的关键帧都是它的后代，因此code中从第一个关键帧开始寻找子关键帧，就一定能够遍历到所有的关键帧。
					2.3 对所有的地图点开始遍历，如果它的mnBAGlobalForKF==nLoopKF，也就是经过了GlobalBundleAdjustemnt，直接将坐标pMP->mPosGBA写入地图点中即可；否则，获得这个地图点的参考关键帧，如果这个关键帧的mnBAGlobalForKF!=nLoopKF，那么跳过，没有基准对地图点进行更新；否则，利用GlobalBundleAdjustemnt优化前后的位姿更新地图点，也就是先使用GlobalBundleAdjustemnt优化前的位姿，将地图点投影到参考关键帧，再通过GlobalBundleAdjustemnt优化后的位姿计算新的坐标，并将这个坐标写到地图点中

		3.5 其他相关内容
			3.5.1 使用FeatureVector 避免了所有特征点的两两匹配，只比较同一个节点下的特征点，极大加速了匹配效率，至于匹配精度，论文《Bags of Binary Words for Fast Place Recognition in Image Sequences 》中提到在26292 张图片里的 false positive  为0，说明精度是有保证的。实际应用中效果非常不错

			3.5.2 系统需要提前加载离线训练好的词袋字典，增加了存储空间。但是带来的优势远大于劣势，而且也有不少改进方法比如用二进制存储等来压缩词袋，减少存储空间，提升加载速度。

			3.5.3 BOW一般用 BRIEF描述子
				1. 速度方面:
					因为计算和匹配都非常快，论文中说大概一个关键点计算256位的描述子只需要17.3μs因为都是二进制描述子，距离描述通过汉明距离，使用异或操作即可，速度非常快。而SIFT, SURF 描述子都是浮点型，需要计算欧式距离，会慢很多。在IntelCorei7，2.67GHzCPU上，使用FAST+BRIEF特征，在26300帧图像中特征提取+词袋位置识别耗时 22ms 每帧。
				2. 在精度方面，先上结论：闭环效果并不比SIFT, SURF之类的高精度特征点差

			3.5.4 字典的离线训练
				vocabulary tree（也称为字典）首先图像提取ORB 特征点，将描述子通过 k-means 进行聚类，根据设定的树的分支数和深度，从叶子节点开始聚类一直到根节点，最后得到一个非常大的 vocabulary tree
				1. 遍历所有的训练图像，对每幅图像提取ORB特征点
				2. 设定vocabulary tree的分支数K和深度L。将特征点的每个描述子用 K-means聚类，变成 K个集合，作为vocabulary tree 的第1层级，然后对每个集合重复该聚类操作，就得到了vocabulary tree的第2层级，继续迭代最后得到满足条件的vocabulary tree，它的规模通常比较大，比如ORB-SLAM2使用的离线字典就有108万+ 个节点。
				3. 离根节点最远的一层节点称为叶子或者单词 Word。根据每个Word 在训练集中的相关程度给定一个权重weight，训练集里出现的次数越多，说明辨别力越差，给与的权重越低。
				4. 节点保存着：NodeId parent_nodeid children_nodeid 256维度的描述子 word_id(叶子节点有) WordValue_weight(叶子节点才有的Word权重)
				5. TF-IDF：频率-逆文档频率，是文本检索中常用的一种加权方式，也用于BoW模型中。得分为：TF_i * IDF_i
					TF部分的思想是，某单词在一副图像中经常出现，它的区分度就高，计算公式为：
						TF_i = n_i/n，其中n_i表示某幅图像中某个单词出现的次数，n表示某幅图像中所有的单词
					IDF的思想是某单词在字典中出现的频率越低，分类图像时区分度越高，计算公式为：
						IDF_i = log(n / n_i)，其中n表示字典中所有特征的数目，n_i表示某个叶子节点所含有的特征的数目
				6. 对每一章图像计算词汇向量(BowVector)和特征向量(FeatureVector)
					1. BowVector：map<WordId, WordValue>，保存每一个特征对应的叶子节点的wordid和权重(有序，key)
					2. FeatureVector：map<NodeId, std::vector<unsigned int>>，对每一个特征，根据levelsup计算这个特征点归属的叶子节点的levelsup-1级父亲节点的nodeid（这样做的理由是，如果对某个word计算匹配，如果对所有word遍历，速度肯定会非常慢，但是如果我们对归属于某一个FeatureVector（待查询的word也在这个FeatureVector下）下的所有word进行遍历，无疑速度会快很多，levelsup控制着速度和精度之间的权衡，levelsup越大，搜索的范围也就越大，精度也就越高，耗时也就越大），由于可能有多个特征点对应相同的nodeid，因此map的值为vector，保存的是特征点的下标索引(有序，key)；可以用来搜索匹配，这个将是非常快的

	4. 系统运行实例
		ORB-SLAM2 Mono
		./Examples/Monocular/mono_tum Vocabulary/ORBvoc.txt Examples/Monocular/TUM1.yaml /home/xiongchao/studying/SLAM/ORB-SLAM/dataset/rgbd_dataset_freiburg1_xyz/

		./Examples/Monocular/visualization Vocabulary/ORBvoc.txt Examples/Monocular/TUM1.yaml /home/xiongchao/studying/SLAM/ORB-SLAM/dataset/rgbd_dataset_freiburg1_xyz/

		./Examples/Monocular/mono_tum Vocabulary/ORBvoc.txt Examples/Monocular/settings.yaml /home/xiongchao/job_case/data/1/images/LW433B100K1000430000000011609115212821/

		./Examples/Monocular/mono_kitti Vocabulary/ORBvoc.txt Examples/Monocular/settings.yaml /home/xiongchao/job_case/data/1/images/LW433B100K1000430000000011609115212821/

		./Examples/Monocular/mono_kitti Vocabulary/ORBvoc.txt Examples/Monocular/KITTI00-02.yaml /home/xiongchao/studying/SLAM/data/data_odometry_color/dataset/sequences/00


		./Examples/Monocular/mono_tum Vocabulary/ORBvoc.txt Examples/Monocular/TUM1.yaml /home/xiongchao/job_case/data/1/images/LW433B100K1000430000000011609115212821/


		rosrun ORB_SLAM2 Stereo Vocabulary/ORBvoc.txt Examples/Stereo/EuRoC.yaml true


		rosbag play --pause /home/xiongchao/studying/SLAM/ORB-SLAM/ORB_SLAM2/MH_01_easy.bag /cam0/image_raw:=/camera/left/image_raw /cam1/image_raw:=/camera/right/image_raw


		 rosbag play --pause /home/teamo/ORB_SLAM /MH_ _easy.bag
		/cam /image_raw:=/camera/left/image_raw
		/cam /image_raw:=/camera/right/image_raw


		ORB-SLAM2 RGB-D:
		./Examples/RGB-D/rgbd_tum Vocabulary/ORBvoc.txt Examples/RGB-D/TUM1.yaml ../../dataset/rgbd_dataset_freiburg1_desk ../../dataset/rgbd_dataset_freiburg1_desk/associations.txt			


地图点云保存的信息：
	1. 世界系坐标
	2. 方向：所有观测到这个地图点的平均视线方向
	3. 描述子
	4. [dmin, dmax]，dmax = d_m * 1.2^m; dmin = d_m * 1.2^(m - 7) = dmax / (scale^(nlevels - 1)); 其中d_m表示地图点到参考关键帧的距离，m表示当前帧的特征点在金字塔的层数

关键帧保存的信息：
	1. 位姿T
	2. 内参：主点和焦距


疑惑：
	2. sift会在每一层上提取关键点吗
	3. 查看colmap中sift特征点的提取和匹配的相关细节，如提取的数量，相关的阈值等等
	5. 重点关注什么时候会用到词袋，使用sift的时候需要全部替换称flann搜索


解释：
	1. 已经有GetFeaturesInArea了，为什么还要使用基于词袋的搜索（主要是基于FeatureVector），是因为GetFeaturesInArea可以用于运动较小，比如初始化的两帧的时候，在局部建图中，将共视图中的关键帧与当年关键帧进行匹配的时候，是不能用GetFeaturesInArea的，因为半径实在很难确定；
	2. 如果替换为sift特征，但是没有sift词典的话，就是用flann算法做特征匹配，另外有sift词典的bin文件，结构未知，简历里面最好别写
	3. 在colmap中地图点没有描述子，因为三维重建图片没有顺序，因此不会有跟踪的过程，而是每次都拿两张图片进行匹配，然后其中一张图片有三维点，就做epnp求位姿；而在orb-slam2中是有一个初始的R t然后根据这个关系将三维点往图片投影获得2D-3D匹配关系，从而建立epnp进行优化
	4. 跟踪阶段不产生新的地图点，局部建图线程去做新的地图点的生成


运行参数：
2438.792236 2438.792236 1915.260864 1083.111084  -- Mo1b
1461.6549982652518, 1461.6549982652518, 640, 360  -- M01


git: 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